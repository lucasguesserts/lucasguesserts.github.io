---
title: Solving Knapsack problem using BRKGA and irace
summary: This tutorial introduces the Knapsack problem, presents models to solve it, and compares them. It goes in-depth on the Biased Random-Key Genetic Algorithm (BRKGA) and the optimization of its parameters using irace.
date: 2024-02-02
math: true
image:
  placement: 1
tags:
  - combinatorial optimization
  - genetic algorithm
  - linear programming
---

## Table of Contents

- [Table of Contents](#table-of-contents)
- [Knapsack Problem](#knapsack-problem)
- [Instances](#instances)
- [Models](#models)
  - [Greedy Algorithm](#greedy-algorithm)
  - [Integer Linear Programming (ILP)](#integer-linear-programming-ilp)
  - [BRKGA](#brkga)
    - [Genetic  Algorithm-Specific Definitions](#genetic--algorithm-specific-definitions)
    - [BRKGA Specific Definitions](#brkga-specific-definitions)
  - [Comparing Models](#comparing-models)
- [Iterated Racing for Automatic Algorithm Configuration (irace)](#iterated-racing-for-automatic-algorithm-configuration-irace)
  - [Problem](#problem)
  - [Solution](#solution)
  - [Optimizing BRKGA with irace](#optimizing-brkga-with-irace)
- [Conclusion](#conclusion)
- [References and Links](#references-and-links)

## Knapsack Problem

The knapsack problem is a combinatorial optimization problem where the goal is to maximize the value in a knapsack with limited capacity by placing valuable items into it.

Let:

1. $I$ be a set of items;
2. $w_i \in \mathbb{Z}^*_+$ be the weight of item $i \in I$;
3. $p_i \in \mathbb{Z}^*_+$ be the profit of item $i \in I$;
4. $C \in \mathbb{Z}^*_+$ be the capacity of the knapsack;
5. $x_i$ be a binary variable that indicates if item $i \in I$ is in the knapsack;

(Notice that one specified the values of $w_i$, $p_i, C$ to be integers for simplicity, but the problem can be generalized to real numbers.)

The knapsack problem can be formulated as an integer linear programming problem:

$$
\begin{align*}
    \max & \sum_{i \in I} p_i x_i \\\\
    \text{subject to} & \sum_{i \in I} w_i x_i \leq C \\\\
    & x_i \in \{0, 1\} \quad \forall i \in I
\end{align*}
$$

To avoid trivial cases, all instances to be tested will satisfy:

1. the total weight of all items exceeds the capacity of the knapsack: $c < \displaystyle\sum\limits_{i \in I} w_i$;
2. all items fit, alone, into the knapsack: $\forall i \in I \left(w_i \leq C\right)$.

## Instances

Here we are going to use the instances generated by [Jorik Jooken, Pieter Leyman, Patrick De Causmaecker](#references-and-links). We are not going into the details of how the instances are generated, but the authors claim that they are hard instances for the 0-1 knapsack problem. For more information, see the authors' paper.

You can download [here is the list of instances selected for this tutorial](./instances.csv).

## Models

The focus here is to solve the problem using BRKGA. However, for comparison purposes, two other models are going to be developed:

1. greedy algorithm;
2. integer linear programming;
3. BRKGA;

### Greedy Algorithm

1. associate to each item $i \in I$ a relative profit value $r_i = \dfrac{p_i}{w_i}$;
2. sort the items in decreasing order of $r_i$;
3. add the items to the knapsack in that order until no item fits;

### Integer Linear Programming (ILP)

The integer linear programming model is the same as the one presented in the [Knapsack Problem section](#knapsack-problem). It can be implemented with any optimization solver for integer linear programming. I chose to use Gurobi 11.

### BRKGA

#### Genetic  Algorithm-Specific Definitions

Let $I$ be a set of items and $n$ be the number of items, $n = \left| I \right|$. Define:

1. **Phenotype Search Space**: the set of possible solutions. Here it is defined as a subset of $I$ such that all items fit in the knapsack:
   $$ \mathcal{P} = \left\lbrace x \subseteq I \ \Big| \ \displaystyle\sum\limits_{i \in x} w_i \leq C \right\rbrace $$

2. **Phenotype or Individual**: an element $x$ of the Phenotype Search Space $x \in \mathcal{P}$;

3. **Allele**: the values that will be used to create the encoding of the Phenotypes. Here it is defined as a value $a$ between $0$ and $1$:
   $$ \mathcal{A} = \left\lbrace a \in \mathbb{R} \ | \ 0 \leq a \leq 1 \right\rbrace $$
   (This is the encoding required by the BRKGA);

4. **Genotype Search Space**: the set of possible encodings. Here it is defined as a list of $n$ alleles:
    $$ \mathcal{G} = \mathcal{A}^n $$
    Notice that $|\mathcal{G}|$ is infinite, whereas $|\mathcal{P}|$ is finite;

5. **Genotype or Chromosome**: an element $y$ of the Genotype Search Space $y \in \mathcal{G}$:
   1. $y$ is a concatenation of $n$ alleles: $y = y_1\dots y_n$;
   2. each of the $n$ elements $y_i$ is known as a **Gene**;

6. **Genotype-Phenotype Mapping**: a function $m$ that maps a chromosome to an individual:
   $$ m: \mathcal{G} \rightarrow \mathcal{P} $$
   Here $m$ is defined to work as follows:
   1. sort the items in decreasing order of the gene values;
   2. add the items to the knapsack in that order until no item fits;

   (Notice that $m$ is not a bijection, as there are many genotypes that map to the same phenotype);

7. **objective function**: a function $f$ that maps a phenotype to a real number. Here it is defined as the total profit of the items in the knapsack:
   $$ f: \mathcal{P} \rightarrow \mathbb{R} $$
   $$ f(x) = \displaystyle\sum\limits_{i \in x} p_i $$

8. **fitness function**: a function $g$ that maps a genotype to a real number. It is defined as the composition $g = f \circ m$:
   $$ g: \mathcal{G} \rightarrow \mathbb{R} $$
   $$ g(y) = f(m(y))$$

#### BRKGA Specific Definitions

The Biased Random-Key Genetic Algorithm (BRKGA), more specifically the `brkga_mp_ipr_cpp` library used here, requires some parameters to be defined. The parameters as well as their corresponding values are summarized in Table 1 below.

{{< table path="brkga_initial_parameters.csv" header="true" caption="Table 1: Initial parameters of the BRKGA" >}}

For this tutorial, the following features of the `brkga_mp_ipr_cpp` are disabled (so the related parameters are not specified in the Table):

1. implicit path relinking;
2. multiple populations;
3. shaken population;
4. reset population;

### Comparing Models

For comparing the performance of the genetic algorithm with greedy, for each instance, the profit of the BRKGA solution is divided by the profit of the Greedy solution, and then one takes the average of all values. The value, if greater than 1, indicates that the BRKGA solution is better than the Greedy solution, and if less than 1, indicates that the Greedy solution is better than the BRKGA solution. The same is done for the Integer Linear Programming Model (ILP).

For the ILP, one sets a high time limit and a low tolerance for the solution so that the profit reported is optimal or as close as possible to it. Thus one expects the value to be reported to be lower than 1.

The results are below:

| BRKGA / ILP | BRKGA / Greedy |
|-------------|----------------|
| 0.9983115   | 1.0043208      |

## Iterated Racing for Automatic Algorithm Configuration (irace)

### Problem

Genetic Algorithms are nice! Given the [specific definitions](#brkga-specific-definitions), it is simply a matter of running the algorithm. However, it is highly dependent on the parameters, in the sense that for different problems, even for different instances of the same problem, the best set of parameters can be (most likely are) different.

That is the problem proposed here. One can try different sets of parameters and see which one performs better given the instances. But how does one know which set of parameters to try? And how does one know when to stop trying?

In practice, values are chosen by intuition:

1. large populations increase the search space and so the likelihood of finding good solutions, but it also increases the runtime;
2. high mutation rates increase diversity, but it loses in intensification;

Intuition can take one just so far. So it is clear that one requires a good procedure so to find parameters "good enough".

That is the Automated Offline Parameter Tuning Problem: to adjust the parameters and heuristics before solving.

### Solution

According to Hoos, there are three main approaches to solving the problem: Racing, ParamILS, and Sequential Model-Based Optimisation (SMBO). All of them propose different procedures to explore the space of possible configurations, exploit the information gathered, and decide which configurations are better.

For our purposes, we are going to use a specific implementation: Iterated Racing for Automatic Algorithm Configuration (irace).

irace receives as input:

1. a set of instances;
2. a configurable algorithm;
3. a set of parameters and their possible values;

It then tunes the parameters by finding the most appropriate settings.

In practice, it means that we are going to give it the required data and it will return to us the best set of parameters for the BRKGA.

### Optimizing BRKGA with irace

Let's run irace with the setup below and let's give it 10 minutes to run:

{{< table path="irace_configs.csv" header="true" caption="Table 1: Initial parameters of the BRKGA" >}}

We get the following configuration ([check out here the irace logs](./irace_logs.txt)):

{{< table path="irace_results.csv" header="true" caption="Table 2: Results of irace" >}}

Running again the [comparison of models](#comparing-models), but using the parameters of configuration 1:

|          | BRKGA / ILP | BRKGA / Greedy |
|----------|-------------|----------------|
| previous | 0.9983115   | 1.0043208      |
| current  | 0.9990564   | 1.0050670      |

We can see that the new configuration is better than the previous one. It is difficult, however, to say how much better it is because the difference is very small. That is a reflex of how the instances are generated: they have groups of large objects, which makes the difference between a good solution and the optimal one small.

## Conclusion

The effectiveness of BRKGA is dependent on choosing specific parameters, posing a challenge in finding optimal settings for diverse instances. Introducing Iterated Racing for Automatic Algorithm Configuration (irace) as a solution, the article highlights the systematic and automated approach of irace in efficiently exploring parameter spaces, resulting in improved BRKGA performance.

The comparison of configurations and irace's application underscores its effectiveness in identifying parameter settings that enhance algorithmic solutions. In practice, irace serves as a valuable tool for researchers and practitioners, offering a systematic means to fine-tune parameters and bolster the adaptability and robustness of genetic algorithms across various combinatorial optimization challenges.

## References and Links

1. Knapsack

   1. [1990 - Knapsack problems: algorithms and computer implementations - Silvano Martello, Paolo Toth](https://dl.acm.org/doi/book/10.5555/98124);
   2. [2004 - Knapsack Problems - Hans Kellerer , Ulrich Pferschy , David Pisinger](https://link.springer.com/book/10.1007/978-3-540-24777-7);

2. Instances Generation

   1. [2022 - A new class of hard problem instances for the 0–1 knapsack problem - Jorik Jooken, Pieter Leyman, Patrick De Causmaecker](https://doi.org/10.1016/j.ejor.2021.12.009);
   2. [My fork of the Instance Generator](https://github.com/lucasguesserts/knapsackProblemInstances);
   3. [Instance Generator](https://github.com/JorikJooken/knapsackProblemInstances);

3. Linear Programming

   1. Linear Programming - Vasek Chvátal;
   2. Introduction to Linear Optimization - Bertsimas and Tsitsiklis;
   3. Integer and Combinatorial Optimization - Laurence A. Wolsey, George L. Nemhauser;

4. Gurobi

   1. [Gurobi website](https://www.gurobi.com/);
   2. [Gurobi C++ API](https://www.gurobi.com/documentation/11.0/refman/cpp_api_details.html);
   3. [Gurobi Diet example in C++](https://www.gurobi.com/documentation/current/examples/diet_cpp_cpp.html);

5. BRKGA - brkga_mp_ipr_cpp

   1. Chapter 5 Genetic Algorithms - Colin R. Reeves (I don't know the book);
   2. [brkga_mp_ipr_cpp github](https://github.com/ceandrade/brkga_mp_ipr_cpp/);
   3. [brkga_mp_ipr_cpp documentation](https://ceandrade.github.io/brkga_mp_ipr_cpp/);

6. irace

   1. [irace website](https://mlopez-ibanez.github.io/irace/);
   2. [irace repository](https://github.com/MLopez-Ibanez/irace);
   3. [irace R package page](https://www.rdocumentation.org/packages/irace/versions/3.5);
   4. [2012 - Autonomous Search - Youssef Hamadi, Eric Monfroy, Frédéric Saubion](https://dx.doi.org/10.1007/978-3-642-21434-9);
      1. [Chapter 3 - Automated Algorithm Configuration and Parameter Tuning - Holger H. Hoos](https://dx.doi.org/10.1007/978-3-642-21434-9_3);
